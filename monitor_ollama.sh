#!/bin/bash
# Script para monitorar atividade do Ollama em tempo real

echo "üîç Monitorando Ollama (Ctrl+C para sair)..."
echo ""
echo "Modelos carregados e suas m√©tricas:"
echo "----------------------------------------"

while true; do
    clear
    echo "üîç Status do Ollama - $(date '+%H:%M:%S')"
    echo "========================================"
    echo ""
    
    # Mostra processos do Ollama
    echo "üìä Processos:"
    ps aux | grep "[o]llama" | grep -v grep | awk '{printf "   PID: %s | CPU: %s%% | MEM: %s%%\n", $2, $3, $4}' || echo "   Nenhum processo ativo"
    
    echo ""
    echo "ü§ñ Modelos em uso:"
    
    # Lista modelos rodando (atrav√©s de chamadas √† API)
    response=$(curl -s http://localhost:11434/api/ps 2>/dev/null)
    if [ $? -eq 0 ] && [ ! -z "$response" ]; then
        echo "$response" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    if 'models' in data and len(data['models']) > 0:
        for model in data['models']:
            name = model.get('name', 'unknown')
            size = model.get('size', 0)
            size_mb = size / (1024*1024)
            print(f'   ‚úì {name} ({size_mb:.1f} MB)')
    else:
        print('   Nenhum modelo em execu√ß√£o no momento')
except:
    print('   Aguardando requisi√ß√µes...')
" 2>/dev/null || echo "   Aguardando requisi√ß√µes..."
    else
        echo "   ‚ö†Ô∏è  Ollama n√£o est√° respondendo"
    fi
    
    echo ""
    echo "üìà √öltimas requisi√ß√µes:"
    # Tenta pegar logs recentes se dispon√≠vel
    tail -n 3 ~/.ollama/logs/server.log 2>/dev/null | sed 's/^/   /' || echo "   (logs n√£o dispon√≠veis)"
    
    echo ""
    echo "----------------------------------------"
    echo "Pressione Ctrl+C para sair"
    
    sleep 2
done

